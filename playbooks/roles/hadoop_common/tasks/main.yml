---
#
# edX Configuration
#
# github:     https://github.com/edx/configuration
# wiki:       https://openedx.atlassian.net/wiki/display/OpenOPS
# code style: https://openedx.atlassian.net/wiki/display/OpenOPS/Ansible+Code+Conventions
# license:    https://github.com/edx/configuration/blob/master/LICENSE.TXT
#
#
#
# Tasks for role hadoop_common
# 
# Overview:
# 
# This role installs all hadoop services onto the machine. Note that this should
# be used to configure all machines in a hadoop cluster. It does not perform
# any role-specific actions such as formatting the namenode etc.
#
# Dependencies:
#
# oraclejdk: Not strictly required, but we tend to trust it more than openjdk.
#

- name: install system packages
  apt:
    pkg: "{{ item }}"
    state: present
  with_items: "{{ hadoop_common_debian_pkgs }}"
  tags:
    - install
    - install:system-requirements

- name: ensure group exists
  group:
    name: "{{ hadoop_common_group }}"
    system: yes
    state: present
  tags:
    - install
    - install:system-requirements

- name: ensure user exists
  user:
    name: "{{ hadoop_common_user }}"
    group: "{{ hadoop_common_group }}"
    home: "{{ HADOOP_COMMON_USER_HOME }}"
    createhome: yes
    shell: /bin/bash
    system: yes
    generate_ssh_key: yes
    state: present
  tags:
    - install
    - install:system-requirements

- name: ensure user is in sudoers
  lineinfile:
    dest: /etc/sudoers
    state: present
    regexp: '^%hadoop ALL\='
    line: '%hadoop ALL=(ALL) NOPASSWD:ALL'
    validate: 'visudo -cf %s'
  tags:
    - install
    - install:system-requirements

- name: check if downloaded and extracted
  stat:
    path: "{{ HADOOP_COMMON_HOME }}"
  register: extracted_hadoop_dir
  tags:
    - install
    - install:system-requirements

- name: distribution downloaded
  get_url:
    url: "{{ hadoop_common_dist.url }}"
    dest: "{{ hadoop_common_temporary_dir }}"
    sha256sum: "{{ hadoop_common_dist.sha256sum }}"
  when: not extracted_hadoop_dir.stat.exists
  tags:
    - install
    - install:system-requirements

- name: distribution extracted
  shell: "tar -xzf {{ hadoop_common_temporary_dir }}/{{ hadoop_common_dist.filename }} && chown -R {{ hadoop_common_user }}:{{ hadoop_common_group }} hadoop-{{ HADOOP_COMMON_VERSION }}"
  args:
    chdir: "{{ HADOOP_COMMON_USER_HOME }}"
  when: not extracted_hadoop_dir.stat.exists
  tags:
    - install
    - install:system-requirements

- name: versioned directory symlink created
  file:
    src: "{{ HADOOP_COMMON_USER_HOME }}/hadoop-{{ HADOOP_COMMON_VERSION }}"
    dest: "{{ HADOOP_COMMON_HOME }}"
    owner: "{{ hadoop_common_user }}"
    group: "{{ hadoop_common_group }}"
    state: link
  tags:
    - install
    - install:system-requirements

- name: configuration installed
  template:
    src: "{{ item }}.j2"
    dest: "{{ HADOOP_COMMON_CONF_DIR }}/{{ item }}"
    mode: 0640
    owner: "{{ hadoop_common_user }}"
    group: "{{ hadoop_common_group }}"
  with_items:
    - hadoop-env.sh
  tags:
    - install
    - install:system-requirements

- name: hadoop env file exists
  file:
    path: "{{ hadoop_common_env }}"
    state: touch
    owner: "{{ hadoop_common_user }}"
    group: "{{ hadoop_common_group }}"
  tags:
    - install
    - install:system-requirements

- name: env vars sourced in bashrc
  lineinfile:
    dest: "{{ HADOOP_COMMON_USER_HOME }}/.bashrc"
    state: present
    regexp: "^. {{ hadoop_common_env }}"
    line: ". {{ hadoop_common_env }}"
    insertbefore: BOF
  tags:
    - install
    - install:system-requirements

- name: env vars sourced in hadoop env
  lineinfile:
    dest: "{{ hadoop_common_env }}"
    state: present
    regexp: "^. {{ HADOOP_COMMON_CONF_DIR }}/hadoop-env.sh"
    line: ". {{ HADOOP_COMMON_CONF_DIR }}/hadoop-env.sh"
  tags:
    - install
    - install:system-requirements
